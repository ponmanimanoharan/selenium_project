{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ponmani manoharan\\Desktop\\Data Trained\\Internship\\web scrapping\\2\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position.\n",
    "In “Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    #get the url\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #search the input box using id\n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Analyst\")\n",
    "    time.sleep(2)\n",
    "    #search the location\n",
    "    search_location = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    search_location.send_keys(\"Bangalore\")\n",
    "    time.sleep(2)\n",
    "    #click the button\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class ='btn']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    #search the title\n",
    "    titles = driver.find_elements_by_xpath(\"//a[@class ='title fw500 ellipsis']\")\n",
    "    job_title = [x.text for x in titles]\n",
    "    time.sleep(2)\n",
    "    #search the company name\n",
    "    comp = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "    company  = [x.text for x in comp]\n",
    "    time.sleep(2)\n",
    "    #search the required experience\n",
    "    exp = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "    experience = [x.text for x in exp]\n",
    "    time.sleep(2)\n",
    "    #search the job location\n",
    "    location = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    job_location = [x.text for x in location]\n",
    "    time.sleep(2)\n",
    "    #return a dictionary \n",
    "    return dict(job_title = job_title[:10] , company_name = company[:10], experience_required = experience[:10], job_location = job_location[:10])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dictionary\n",
    "ans_one = answer_one()\n",
    "#create pandas data frame\n",
    "Question_one =  pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_one.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SA Tech Software (I) Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analyst - Google Analytics</td>\n",
       "      <td>H and M Hennes and Mauritz (P) Ltd.</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Regular Business Analyst / Data Analyst</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst @ Flipkart on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                     Data Analyst - Informatica MDM   \n",
       "2  Assistant Vice President - MIS & Reporting ( B...   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "6                    Data analyst - Google Analytics   \n",
       "7     Senior/Regular Business Analyst / Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9     Hiring For Data Analyst @ Flipkart on Contract   \n",
       "\n",
       "                                        company_name experience_required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                Shell India Markets Private Limited             6-9 Yrs   \n",
       "2  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...           12-18 Yrs   \n",
       "3                           Myntra Designs Pvt. Ltd.             3-6 Yrs   \n",
       "4                     SA Tech Software (I) Pvt. Ltd.             1-3 Yrs   \n",
       "5   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd             2-4 Yrs   \n",
       "6                H and M Hennes and Mauritz (P) Ltd.             4-7 Yrs   \n",
       "7                                             Luxoft             3-6 Yrs   \n",
       "8                  Flipkart Internet Private Limited             1-3 Yrs   \n",
       "9                  Flipkart Internet Private Limited             2-6 Yrs   \n",
       "\n",
       "                                        job_location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                        Mumbai, Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4  Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position\n",
    "In “Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    #create empty list \n",
    "    urls = []\n",
    "    desc = []\n",
    "    #get the url\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #search the input box uxing id of the html tag\n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    time.sleep(2)\n",
    "    #search the location using id of the html tag\n",
    "    search_location = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    search_location.send_keys(\"Bangalore\")\n",
    "    time.sleep(2)\n",
    "    #click search button\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class ='btn']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    #search for the job title\n",
    "    titles = driver.find_elements_by_xpath(\"//a[@class ='title fw500 ellipsis']\")\n",
    "    job_title = [x.text for x in titles]\n",
    "    time.sleep(2)\n",
    "    #search for the company name\n",
    "    comp = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "    company  = [x.text for x in comp]\n",
    "    time.sleep(2)\n",
    "    #search for the job_location\n",
    "    location = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    job_location = [x.text for x in location]\n",
    "    time.sleep(2)\n",
    "    #using a for loop to ectract urls\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class ='info fleft']/a\"):\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    time.sleep(2)\n",
    "    #using the extracted urls find full job description.\n",
    "    for i in urls[:10]:\n",
    "        driver.get(i)\n",
    "        time.sleep(4)\n",
    "        try:\n",
    "            job_decription = driver.find_element_by_xpath(\"//section[@class = 'job-desc']\") \n",
    "            desc.append(job_decription.text)\n",
    "        except NoSuchElementException:\n",
    "            desc.append('-')\n",
    "    time.sleep(2)\n",
    "    #return a dictionary \n",
    "    return dict(job_title = job_title[:10], company = company[:10], job_location = job_location[:10], job_description = desc) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Job description\\nWe wont say we can predict th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nResponsibilities and Key Resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\n\\n\\nWe are seeking an outstan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Job description\\nDear Aspirant,\\n\\nGreetings f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                    Senior Data Scientist, Modeling   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                Lead Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                         SDE Lead Data Scientist-L3   \n",
       "8        Computational Design Lead Data Scientist-L3   \n",
       "9  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "\n",
       "                                             company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                                            Nielsen   \n",
       "2                          Xoriant Solutions Pvt Ltd   \n",
       "3                              Philips India Limited   \n",
       "4                             IBM India Pvt. Limited   \n",
       "5                     Intel Technology India Pvt Ltd   \n",
       "6                             Oracle India Pvt. Ltd.   \n",
       "7                  Huawei Technologies India Pvt Ltd   \n",
       "8                  Huawei Technologies India Pvt Ltd   \n",
       "9  GlobalEdx Learning and Technology Solution Pvt...   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "2  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description\\nJob Role : Data Scientist/Dat...  \n",
       "1  Job description\\nWe wont say we can predict th...  \n",
       "2                                                  -  \n",
       "3  Job description\\nResponsibilities and Key Resu...  \n",
       "4                                                  -  \n",
       "5  Job description\\n\\n\\nWe are seeking an outstan...  \n",
       "6                                                  -  \n",
       "7  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "8  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "9  Job description\\nDear Aspirant,\\n\\nGreetings f...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dictionary\n",
    "ans_two = answer_two()\n",
    "#create pandas DataFrame\n",
    "Question_two =  pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_two.items()]))\n",
    "Question_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    #fetch the url\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #search the input box using id of html tag\n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    time.sleep(2)\n",
    "    #click the search button using id of html tag\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class ='btn']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    #filter funtion to slect specific categories \n",
    "    filter_button_one = driver.find_elements_by_xpath(\"//p[@class = 'grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "    #for loop used to select on option from multiple options\n",
    "    for x in filter_button_one:\n",
    "        if x.text == 'Delhi / NCR':\n",
    "            x.click()\n",
    "            break\n",
    "    time.sleep(3)\n",
    "    #try-catch block to identify exceptions\n",
    "    try:\n",
    "        for x in filter_button_one:\n",
    "            if x.text == '3-6 Lakhs':\n",
    "                x.click()\n",
    "                break\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \", e)\n",
    "    #search to extract title\n",
    "    titles = driver.find_elements_by_xpath(\"//a[@class ='title fw500 ellipsis']\")\n",
    "    job_title = [x.text for x in titles]\n",
    "    time.sleep(2)\n",
    "    #search to extract company name\n",
    "    comp = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "    company  = [x.text for x in comp]\n",
    "    time.sleep(2)\n",
    "    #search to extract location\n",
    "    location = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    job_location = [x.text for x in location]\n",
    "    time.sleep(2)\n",
    "    #search to extract exp\n",
    "    exp = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "    experience = [x.text for x in exp]\n",
    "    time.sleep(2)\n",
    "    #returns adictionary \n",
    "    return dict(job_title = job_title[:10], company_name = company[:10], experience_required = experience[:10], job_location = job_location[:10])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised:  Message: stale element reference: element is not attached to the page document\n",
      "  (Session info: chrome=90.0.4430.212)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Decision Point</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Burgeon IT Services Pvt ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For an AI Product (Work from Home)</td>\n",
       "      <td>Biz HR IT Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Scientist - AutoML</td>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Platlap Solutions</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>VALIANCE ANALYTICS PRIVATE LIMITED</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                              Senior Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Data Scientist For an AI Product (Work from Home)   \n",
       "4                    Senior Data Scientist, Modeling   \n",
       "5                        Sr. Data Scientist - AutoML   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                   Business Analyst- Data Scientist   \n",
       "9                                 Sr. Data Scientist   \n",
       "\n",
       "                         company_name experience_required  \\\n",
       "0  Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                      Decision Point             3-6 Yrs   \n",
       "2         Burgeon IT Services Pvt ltd            6-11 Yrs   \n",
       "3                 Biz HR IT Solutions             3-5 Yrs   \n",
       "4                             Nielsen             3-7 Yrs   \n",
       "5                  TransOrg Analytics             5-8 Yrs   \n",
       "6                  TransOrg Analytics             3-6 Yrs   \n",
       "7                   Platlap Solutions            5-10 Yrs   \n",
       "8                               Wipro             2-5 Yrs   \n",
       "9  VALIANCE ANALYTICS PRIVATE LIMITED             6-8 Yrs   \n",
       "\n",
       "                                        job_location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                          Gurgaon/Gurugram, Chennai  \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...  \n",
       "3  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...  \n",
       "4  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...  \n",
       "5                                   Gurgaon/Gurugram  \n",
       "6                           Mumbai, Gurgaon/Gurugram  \n",
       "7  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...  \n",
       "8                            Noida, Gurgaon/Gurugram  \n",
       "9                   Bangalore/Bengaluru, Delhi / NCR  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dictionary\n",
    "ans_three = answer_three()\n",
    "# create pandas data frame\n",
    "Question_three = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_three.items()]))\n",
    "Question_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    #fetch the url\n",
    "    url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "    driver.get(url)\n",
    "    time.sleep(60)\n",
    "    #search the input box using id of the html tag\n",
    "    search_job = driver.find_element_by_id(\"sc.keyword\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    time.sleep(2)\n",
    "    #search the input box using id of the html tag\n",
    "    search_location = driver.find_element_by_id(\"sc.location\")\n",
    "    search_location.send_keys(\"Noida\")\n",
    "    time.sleep(2)\n",
    "    #clcik button using id og html tag\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class ='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    # extract the name\n",
    "    name = driver.find_elements_by_xpath(\"//a[@class =' css-l2wjgv e1n63ojh0 jobLink']/span\")\n",
    "    company = [x.text for x in name]\n",
    "    time.sleep(2)\n",
    "    #extract the days\n",
    "    days = driver.find_elements_by_xpath(\"//div[@class ='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    no_of_days = [x.text for x in days]\n",
    "    time.sleep(2)\n",
    "    #extract ratings\n",
    "    ratings = driver.find_elements_by_xpath(\"//span[@class ='css-19pjha7 e1cjmv6j1']\")\n",
    "    rate = [x.text for x in ratings]\n",
    "    time.sleep(2)\n",
    "    #return a dictionary \n",
    "    return  dict(company_name = company[:10], no_of_days = no_of_days[:10], ratings = rate[:10])\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>no_of_days</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apsidata Solutions</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>1d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>26d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Khan Academy</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company_name no_of_days ratings\n",
       "0      Apsidata Solutions         5d     4.3\n",
       "1                   Adobe        24h     4.4\n",
       "2                Ericsson         1d     4.1\n",
       "3          Biz2Credit Inc       30d+     3.8\n",
       "4                Techlive       30d+     5.0\n",
       "5               dunnhumby        24h     4.1\n",
       "6  Data Trained Education         3d     3.6\n",
       "7                 CRMNEXT        14d     4.4\n",
       "8                   Adobe        26d     4.0\n",
       "9            Khan Academy        24h     3.6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dictionary\n",
    "ans_four = answer_four()\n",
    "#create pandas datafarame\n",
    "Question_four = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_four.items()]))\n",
    "Question_four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    #get url\n",
    "    url = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "    driver.get(url)\n",
    "    time.sleep(20)\n",
    "    #search using id\n",
    "    search_job = driver.find_element_by_id(\"KeywordSearch\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    time.sleep(2)\n",
    "    #search using id\n",
    "    search_location = driver.find_element_by_id(\"LocationSearch\")\n",
    "    search_location.send_keys(\"Noida\")\n",
    "    time.sleep(2)\n",
    "    #click using id\n",
    "    search_btn = driver.find_element_by_id(\"HeroSearchButton\")\n",
    "    search_btn.click()\n",
    "    time.sleep(2)\n",
    "    #extract comapny name\n",
    "    titles = driver.find_elements_by_xpath(\"//a[@class ='css-f3vw95 e1aj7ssy3']\")\n",
    "    company = [x.text for x in titles]\n",
    "    time.sleep(2)\n",
    "    #extract salaries\n",
    "    number_of_salaries = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']/span\")\n",
    "    number_salaries = [x.text for x in number_of_salaries]\n",
    "    time.sleep(2)\n",
    "    #extract avergae salaries\n",
    "    average_salary = driver.find_elements_by_xpath(\"//div[@class = 'col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "    average = [x.text.replace(\"\\n\", \"\") for x in average_salary]\n",
    "    time.sleep(2)\n",
    "    #extract min sal\n",
    "    min_sal = driver.find_elements_by_xpath(\"//div[@class ='d-flex mt-xxsm css-79elbk epuxyqn0']/p[1]\")\n",
    "    mini = [x.text for x in min_sal]\n",
    "    time.sleep(2)\n",
    "    #extract max salary\n",
    "    max_sal = driver.find_elements_by_xpath(\"//div[@class ='d-flex mt-xxsm css-79elbk epuxyqn0']/p[2]\")\n",
    "    maxi = [x.text for x in max_sal]\n",
    "    time.sleep(2)\n",
    "    #return dictionary \n",
    "    return (dict(company_name = company[:10], salaries = number_salaries[:10], average_salary = average[:10], minimum = mini[:10], maximum = maxi[:10] ))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>salaries</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>17 salaries</td>\n",
       "      <td>₹ 6,14,306 /yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,250K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533 /yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795 /yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057 /yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781 /yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142 /yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192 /yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221 /yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243 /yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 14,13,288 /yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name     salaries   average_salary  minimum   maximum\n",
       "0  Tata Consultancy Services  17 salaries   ₹ 6,14,306 /yr    ₹343K   ₹1,250K\n",
       "1                  Accenture  14 salaries  ₹ 11,46,533 /yr    ₹577K   ₹2,213K\n",
       "2                        IBM  14 salaries   ₹ 8,97,795 /yr    ₹586K   ₹2,730K\n",
       "3         Ericsson-Worldwide  14 salaries   ₹ 7,38,057 /yr    ₹355K   ₹1,613K\n",
       "4                  Delhivery  14 salaries  ₹ 12,39,781 /yr    ₹450K  ₹11,622K\n",
       "5         UnitedHealth Group  11 salaries  ₹ 13,36,142 /yr  ₹1,069K   ₹1,520K\n",
       "6         Valiance Solutions   9 salaries   ₹ 8,15,192 /yr    ₹502K   ₹1,465K\n",
       "7              ZS Associates   8 salaries  ₹ 11,35,221 /yr    ₹202K   ₹1,809K\n",
       "8                EXL Service   8 salaries  ₹ 11,44,243 /yr    ₹575K   ₹1,520K\n",
       "9     Optum Global Solutions   8 salaries  ₹ 14,13,288 /yr  ₹1,014K   ₹2,149K"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_five = answer_five()\n",
    "#create pandas dataframe\n",
    "Question_Five = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_five.items()]))\n",
    "Question_Five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    #create empty lists\n",
    "    urls = []\n",
    "    b = []\n",
    "    p = []\n",
    "    d = []\n",
    "    pd = []   \n",
    "    #get url\n",
    "    driver.get(\"https://www.flipkart.com/\")\n",
    "    time.sleep(3)\n",
    "    #search products using tag name \n",
    "    search_product = driver.find_element_by_tag_name(\"input\")\n",
    "    search_product.send_keys(\"sunglasses\")\n",
    "    time.sleep(3)\n",
    "    #click search button using xpath\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    #extract brand name\n",
    "    brand_name = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [x.text for x in brand_name]\n",
    "    time.sleep(3)\n",
    "    #extract price\n",
    "    price_all = driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    price = [x.text for x in price_all]\n",
    "    time.sleep(3)\n",
    "    #extract discount\n",
    "    discount = driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']/span\")\n",
    "    discounts = [x.text for x in discount]\n",
    "    time.sleep(3)\n",
    "    #extract description \n",
    "    product_description = driver.find_elements_by_xpath(\"//a[@class= 'IRpwTa']\")\n",
    "    prod = [x.text for x in product_description]\n",
    "    time.sleep(3)\n",
    "    #extract urls\n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a\"):\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    urls = urls[1:10]\n",
    "    time.sleep(3)\n",
    "    #try-catch to extract brand name for different urls \n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            b_n = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in b_n:\n",
    "                b.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(5)\n",
    "    brand = brand + b\n",
    "    time.sleep(5)\n",
    "    #try-catch to extract price for different urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            price_all = driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "            for i in price_all:\n",
    "                p.append(i.text)        \n",
    "    except StaleElementReferenceException as e:\n",
    "            print(\"Exception raised: \",e)\n",
    "    time.sleep(5)\n",
    "    price = price+p\n",
    "    time.sleep(5)\n",
    "    #try-catch to extract dicount for different urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            discount = driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']/span\")\n",
    "        for i in discount:\n",
    "            d.append(i.text)                                   \n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(5)\n",
    "    discounts = discounts +d\n",
    "    time.sleep(5)\n",
    "    #try-catch to extract description for different urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            product_description = driver.find_elements_by_xpath(\"//a[@class= 'IRpwTa']\")\n",
    "        for i in product_description:\n",
    "            pd.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(5)\n",
    "    prod = prod+pd\n",
    "    time.sleep(5)\n",
    "    #return dictionary\n",
    "    return(dict(brand = brand[:100], price = price[:100], discounts = discounts[:100], description = prod[:100]))\n",
    "    \n",
    "                \n",
    "       \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dictionary\n",
    "ans_six = answer_six()\n",
    "#create dataframe\n",
    "sunglasses = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_six.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>discounts</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EYEXACK</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection, Mirrored, Gradient, Riding Glas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bulgaria</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Others Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand price discounts  \\\n",
       "0         EYEXACK  ₹319   84% off   \n",
       "1        bulgaria  ₹449   55% off   \n",
       "2        Fastrack  ₹630   21% off   \n",
       "3  ROZZETTA CRAFT  ₹499   77% off   \n",
       "4  ROZZETTA CRAFT  ₹404   79% off   \n",
       "\n",
       "                                         description  \n",
       "0  UV Protection, Mirrored, Gradient, Riding Glas...  \n",
       "1          Others Rectangular Sunglasses (Free Size)  \n",
       "2   UV Protection Rectangular Sunglasses (Free Size)  \n",
       "3  UV Protection Retro Square Sunglasses (Free Size)  \n",
       "4  UV Protection, Gradient Rectangular Sunglasses...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    #create empty list\n",
    "    urls = []\n",
    "    #get url\n",
    "    url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    #click button\n",
    "    expand_btn = driver.find_element_by_xpath(\"//div[@class ='_3UAT2v _16PBlm']/span\")\n",
    "    expand_btn.click()\n",
    "    time.sleep(3)\n",
    "    #extract review\n",
    "    review = driver.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\")\n",
    "    reviews = [x.text for x in review]\n",
    "    time.sleep(3)\n",
    "    #extract ratings\n",
    "    rating = driver.find_elements_by_xpath(\"//div[@class = '_3LWZlK _1BLPMq']\")\n",
    "    rate = [x.text for x in rating]\n",
    "    time.sleep(3)\n",
    "    #extract full reviews \n",
    "    full = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    full_review = [x.text for x in full]\n",
    "    time.sleep(3)\n",
    "    #extract urls\n",
    "    for x in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\"):\n",
    "        urls.append(x.get_attribute('href'))\n",
    "    urls = urls[2:11]\n",
    "    rev = []\n",
    "    #try-catch block to extract review from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            review = driver.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\")\n",
    "            for i in review:\n",
    "                rev.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    reviews = reviews + rev\n",
    "    rat = []\n",
    "    #try-catch block to extract rating differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            rating = driver.find_elements_by_xpath(\"//div[@class = '_3LWZlK _1BLPMq']\")\n",
    "            for i in rating:\n",
    "                 rat.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    rate = rate + rat\n",
    "    f = []\n",
    "    #try-catch block to extract full-review from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            full = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "            for i in full:\n",
    "                 f.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    full_review = full_review + f\n",
    "    #returns dictionary\n",
    "    return(dict(Reviews = reviews[:100], Ratings = rate[:100], full_review = full_review[:100]))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "                              \n",
    "       \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>5</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great product</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good choice</td>\n",
       "      <td>4</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>5</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>5</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Classy product</td>\n",
       "      <td>5</td>\n",
       "      <td>Superb Product !!!\\nA big and worthy upgrade f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviews Ratings  \\\n",
       "0            Brilliant       5   \n",
       "1     Perfect product!       5   \n",
       "2        Great product       5   \n",
       "3    Worth every penny       5   \n",
       "4          Good choice       4   \n",
       "..                 ...     ...   \n",
       "95            Terrific       5   \n",
       "96  Highly recommended       5   \n",
       "97      Classy product       5   \n",
       "98           Wonderful     NaN   \n",
       "99           Brilliant     NaN   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  Really worth of money. i just love it. It is t...  \n",
       "96  It's my first time to use iOS phone and I am l...  \n",
       "97  Superb Product !!!\\nA big and worthy upgrade f...  \n",
       "98  This is my first ever I phone. Before this I w...  \n",
       "99  I have migrated from OP 7pro... and trust me, ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gets dictionary\n",
    "ans_seven = answer_seven()\n",
    "#create datafarame\n",
    "Iphone = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_seven .items()]))\n",
    "Iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    #get url\n",
    "    driver.get(\"https://www.flipkart.com/\")\n",
    "    time.sleep(3)\n",
    "    #search product by tag name\n",
    "    search_product = driver.find_element_by_tag_name(\"input\")\n",
    "    search_product.send_keys(\"sneakers\")\n",
    "    time.sleep(3)\n",
    "    #click search button\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    #extarct brand name\n",
    "    brand_name = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    brand = [x.text for x in brand_name]\n",
    "    time.sleep(3)\n",
    "    #extract price\n",
    "    price_all = driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "    price = [x.text for x in price_all]\n",
    "    time.sleep(3)\n",
    "    #extract discount\n",
    "    discount = driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']/span\")\n",
    "    discounts = [x.text for x in discount]\n",
    "    time.sleep(3)\n",
    "    #extract product description \n",
    "    product_description = driver.find_elements_by_xpath(\"//a[@class= 'IRpwTa']\")\n",
    "    prod = [x.text for x in product_description]\n",
    "    time.sleep(3)\n",
    "    urls = []\n",
    "    #extarct urls\n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a\"):\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    urls = urls[1:10]\n",
    "    b = []\n",
    "    #try-catch block to extract brand name from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            b_n = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "            for i in b_n:\n",
    "                 b.append(i.text)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    p = []\n",
    "    #try-catch block to extract price from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            price_all = driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "            for i in price_all:\n",
    "                p.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    d = []\n",
    "    #try-catch block to extract discount from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            discount = driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']/span\")\n",
    "\n",
    "            for i in discount:\n",
    "                d.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    pd = []\n",
    "    #try-catch block to extract product description from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            product_description = driver.find_elements_by_xpath(\"//a[@class= 'IRpwTa']\")\n",
    "            for i in product_description:\n",
    "                pd.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    #combining the lists \n",
    "    brand = brand + b\n",
    "    price = price+p\n",
    "    discounts = discounts +d\n",
    "    prod = prod+pd\n",
    "    #return dictionary \n",
    "    return(dict(brand = brand[:100], price = price[:100], discounts = discounts[:100], description = prod[:100]))\n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary\n",
    "ans_eight = answer_eight()\n",
    "#create pandas dataframe\n",
    "sneakers = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_eight.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>discounts</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>₹299</td>\n",
       "      <td>40% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "      <td>Ascend Lite Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHOELIFE</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ESSENCE</td>\n",
       "      <td>₹442</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Fashionable casual sneakers shoes Sneakers For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹419</td>\n",
       "      <td>50% off</td>\n",
       "      <td>casual for men (beige 06) Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand price discounts  \\\n",
       "0       HOTSTYLE  ₹299   40% off   \n",
       "1             TR  ₹599   70% off   \n",
       "2   Robbie jones  ₹379   62% off   \n",
       "3        Numenzo  ₹398   60% off   \n",
       "4         ORICUM  ₹377   62% off   \n",
       "..           ...   ...       ...   \n",
       "95        BRUTON  ₹299   76% off   \n",
       "96         Zorth  ₹599   40% off   \n",
       "97      SHOELIFE  ₹449   55% off   \n",
       "98       ESSENCE  ₹442   55% off   \n",
       "99        BRUTON  ₹419   50% off   \n",
       "\n",
       "                                          description  \n",
       "0                                    Sneakers For Men  \n",
       "1                                    Sneakers For Men  \n",
       "2      Casual Sneakers Shoes For Men Sneakers For Men  \n",
       "3                                    Sneakers For Men  \n",
       "4   Combo pack of 2 casual sneaker shoes for men S...  \n",
       "..                                                ...  \n",
       "95                       Ascend Lite Sneakers For Men  \n",
       "96                                   Sneakers For Men  \n",
       "97                         Men Boxer Sneakers For Men  \n",
       "98  Fashionable casual sneakers shoes Sneakers For...  \n",
       "99         casual for men (beige 06) Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9 : scraping myntra website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_nine():\n",
    "    #get url\n",
    "    url = \"https://www.myntra.com/shoes\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    #click the fliters\n",
    "    driver.find_elements_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")[0].click()\n",
    "    driver.find_elements_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")[0].click()\n",
    "    time.sleep(3)\n",
    "    #get brand name\n",
    "    brand = driver.find_elements_by_xpath(\"//h3[@class ='product-brand']\")\n",
    "    b = [x.text for x in brand ]\n",
    "    time.sleep(3)\n",
    "    #get descrtion\n",
    "    desc = driver.find_elements_by_xpath(\"//h4[@class ='product-product']\")\n",
    "    d = [x.text for x in desc ]\n",
    "    time.sleep(3)\n",
    "    #extract price\n",
    "    price = driver.find_elements_by_xpath(\"//div[@class ='product-price']/span[1]\")\n",
    "    p = [x.text for x in price]\n",
    "    time.sleep(3)\n",
    "    #extract urls \n",
    "    urls = []\n",
    "    for j in driver.find_elements_by_xpath(\"//ul[@class ='pagination-container']/li/a\"):\n",
    "        urls.append(j.get_attribute('href'))\n",
    "    time.sleep(3)\n",
    "    urls = urls[2:11]\n",
    "    b_1 = []\n",
    "    #try-catch block to extract brand name from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            brand = driver.find_elements_by_xpath(\"//h3[@class ='product-brand']\")\n",
    "            for i in brand:\n",
    "                 b_1.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    d_1 = []\n",
    "    #try-catch block to extract desc from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            desc = driver.find_elements_by_xpath(\"//h4[@class ='product-product']\")\n",
    "            for i in desc:\n",
    "                 d_1.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    p_1 = []\n",
    "    #try-catch block to extract price from differnt urls\n",
    "    try:\n",
    "        for x in urls:\n",
    "            driver.get(x)\n",
    "            time.sleep(3)\n",
    "            price = driver.find_elements_by_xpath(\"//div[@class ='product-price']/span[1]\")\n",
    "            for i in price:\n",
    "                 p_1.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Exception raised: \",e)\n",
    "    time.sleep(3)\n",
    "    #combine lists\n",
    "    brand_name = b+b_1\n",
    "    description = d+d_1\n",
    "    price = p+p_1\n",
    "    #return dictionary\n",
    "    \n",
    "    return(dict(brand = brand_name[:100], price = price[:100],  description = description[:100]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shezone</td>\n",
       "      <td>Rs. 699Rs. 999</td>\n",
       "      <td>Women Animal Print Ballerinas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street Style Store</td>\n",
       "      <td>Rs. 599Rs. 799</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marc Loire</td>\n",
       "      <td>Rs. 983Rs. 2399</td>\n",
       "      <td>Women Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catwalk</td>\n",
       "      <td>Rs. 1361Rs. 2095</td>\n",
       "      <td>Women Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marc Loire</td>\n",
       "      <td>Rs. 987Rs. 2599</td>\n",
       "      <td>Women Shimmer Block Heels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 2114Rs. 4499</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 2399Rs. 3999</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 3374Rs. 4499</td>\n",
       "      <td>Men Running Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 1649Rs. 2999</td>\n",
       "      <td>Women CITY TRAINER 3 Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 2499Rs. 4999</td>\n",
       "      <td>Men X_PLR S Sneakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 brand             price                    description\n",
       "0              Shezone    Rs. 699Rs. 999  Women Animal Print Ballerinas\n",
       "1   Street Style Store    Rs. 599Rs. 799           Women Open Toe Flats\n",
       "2           Marc Loire   Rs. 983Rs. 2399                    Women Pumps\n",
       "3              Catwalk  Rs. 1361Rs. 2095                  Women Sandals\n",
       "4           Marc Loire   Rs. 987Rs. 2599      Women Shimmer Block Heels\n",
       "..                 ...               ...                            ...\n",
       "95                Nike  Rs. 2114Rs. 4499             Women Heeled Boots\n",
       "96                Puma  Rs. 2399Rs. 3999           Women Open Toe Flats\n",
       "97            Skechers  Rs. 3374Rs. 4499   Men Running Slip-On Sneakers\n",
       "98                Puma  Rs. 1649Rs. 2999  Women CITY TRAINER 3 Training\n",
       "99                Nike  Rs. 2499Rs. 4999           Men X_PLR S Sneakers\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dictionary\n",
    "ans_nine = answer_nine()\n",
    "#create dataframe\n",
    "black_sneakers = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in ans_nine.items()]))\n",
    "black_sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Enter “Laptop” in the search field and then click the search icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the url\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "#search the procuct using id\n",
    "search_prod = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_prod.send_keys(\"Laptop\")\n",
    "time.sleep(3)\n",
    "#click on search button\n",
    "search_icon = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_icon.click()\n",
    "time.sleep(3)\n",
    "#activate the filter for i7\n",
    "driver.find_elements_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a\")[0].click()\n",
    "               \n",
    "\n",
    "       \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_laptop_i7():\n",
    "    #extract the title\n",
    "    title = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    laptop_title = [x.text for x in title]\n",
    "    time.sleep(3)\n",
    "    time.sleep(3)\n",
    "    #extract the price\n",
    "    price = driver.find_elements_by_xpath(\"//span[@class = 'a-price-whole']\")\n",
    "    laptop_price = [x.text for x in price]\n",
    "    return dict(laptop_title = laptop_title,  laptop_price=laptop_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "i7 = amazon_laptop_i7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear filter\n",
    "driver.find_elements_by_xpath(\"//*[@id='filters']/ul[1]/li[1]/span/a/span[1]\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new fiilter for i9\n",
    "driver.find_elements_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a/span\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_laptop_i9():\n",
    "    title = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    laptop_title_1 = [x.text for x in title]\n",
    "    #extract the title\n",
    "    time.sleep(3)\n",
    "    time.sleep(3)\n",
    "    #extract the title\n",
    "    price = driver.find_elements_by_xpath(\"//span[@class = 'a-price-whole']\")\n",
    "    laptop_price_1 = [x.text for x in price]\n",
    "    return dict(laptop_title = laptop_title_1, laptop_price=laptop_price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "i9 =  amazon_laptop_i9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "i7_data = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in i7.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "i9_data = pd.DataFrame(dict([(keys, pd.Series(values)) for keys, values in i9.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([i7_data,i9_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laptop_title</th>\n",
       "      <th>laptop_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...</td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>53,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>78,593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>3,43,099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...</td>\n",
       "      <td>1,35,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>96,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asus ZenBook UX330 UX330UA-FB088T 13.3-inch La...</td>\n",
       "      <td>80,980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>1,34,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...</td>\n",
       "      <td>99,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dell Gaming-G3 3590 15.6-inch FHD Laptop (9th ...</td>\n",
       "      <td>46,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>1,19,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>61,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>34,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>65,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...</td>\n",
       "      <td>98,440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>37,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>2,16,327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>91,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lenovo 2019 Yoga C930 2-in-1 13.9\" 4K UHD Touc...</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Acer Swift 3X 14\" FHD IPS Display Ultra Thin a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light 11th Gen Core i3 Lap...</td>\n",
       "      <td>42,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light Ryzen 3-3250 Laptop,...</td>\n",
       "      <td>35,695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP 15 Entry Level 15.6-inch (39.62 cms) HD Lap...</td>\n",
       "      <td>26,611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15 Intel Pentium Gold 6405U Processor Entry...</td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...</td>\n",
       "      <td>26,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS VivoBook 14 (2020) Intel Quad Core Pentiu...</td>\n",
       "      <td>42,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP 15 AMD Athlon 15.6\" (39.62cms) HD Laptop (S...</td>\n",
       "      <td>19,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light 11th Gen Core i3 Lap...</td>\n",
       "      <td>50,769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVITA Essential NE14A2INC433-MB 14\" (35.56cms)...</td>\n",
       "      <td>39,939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 15(2021) 5th Gen Ryzen 5 5500U Laptop with ...</td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dell Inspiron 3501 15.6\" (39.62 cms) FHD AG Di...</td>\n",
       "      <td>59,970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HP Chromebook 14a-na0003TU 14-inch (35.56 cms)...</td>\n",
       "      <td>36,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light 11th Gen Core i5 Lap...</td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HP 14 Ultra Thin &amp; Light 14\" (35.56cms) Laptop...</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HP Chromebook 14a-na0002TU Laptop (Celeron N40...</td>\n",
       "      <td>29,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>29,740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Renewed) HP Elitebook Laptop 640G1 Intel Core...</td>\n",
       "      <td>19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lenovo Ideapad Slim 3 AMD Athlon Silver 3050U ...</td>\n",
       "      <td>44,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Renewed) Fujitsu Intel Core i5 3340M 15.6-Inc...</td>\n",
       "      <td>34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lenovo IdeaPad S145 10th Gen Intel Core i5 15....</td>\n",
       "      <td>30,873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ASUS VivoBook 14 (2020) Intel Core i3-1005G1 1...</td>\n",
       "      <td>51,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lenovo Ideapad Slim 3 AMD Ryzen 3 15.6 inch (3...</td>\n",
       "      <td>51,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dell Inspiron 3505 15.6\" FHD Display Laptop (R...</td>\n",
       "      <td>35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HP 14 4th Gen Ryzen 5 5500U 14-inch(35.6 cm) F...</td>\n",
       "      <td>22,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 10th Gen Intel Core i3 1...</td>\n",
       "      <td>40,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ASUS VivoBook 15 (2020), 39.6 cm HD, Dual Core...</td>\n",
       "      <td>62,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light Ryzen 3-3250 Laptop,...</td>\n",
       "      <td>50,856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Asus X509MA-BR270T/ Silver/ Intel Celeron N402...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HP 15 Thin &amp; Light 15.6\" (39.62cms) FHD Laptop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i3 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         laptop_title laptop_price\n",
       "0   Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...       82,490\n",
       "1   Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...       83,990\n",
       "2   Mi Notebook Horizon Edition 14 Intel Core i5-1...       53,999\n",
       "3   HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...       78,593\n",
       "4   HP Pavilion Gaming 10th Gen Intel Core i7 Proc...     3,43,099\n",
       "5   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...       69,990\n",
       "6   Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...     1,35,490\n",
       "7   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...       96,000\n",
       "8   Asus ZenBook UX330 UX330UA-FB088T 13.3-inch La...       80,980\n",
       "9   ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...       29,990\n",
       "10  Life Digital Laptop 15.6-inch (39.62 cms) (Int...     1,34,999\n",
       "11  OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...       99,499\n",
       "12  Dell Gaming-G3 3590 15.6-inch FHD Laptop (9th ...       46,290\n",
       "13  (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...       83,990\n",
       "14  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...     1,19,499\n",
       "15  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...       61,799\n",
       "16  (Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...       84,990\n",
       "17  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...       34,000\n",
       "18  (Renewed) Dell Latitude E6420 14 Inch Laptop (...       77,990\n",
       "19  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...       65,299\n",
       "20  (Renewed) Dell Latitude E7470 14-inch Laptop (...       97,990\n",
       "21  Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...       98,440\n",
       "22  (Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...       83,990\n",
       "23  HP Pavilion (2021) Thin & Light 11th Gen Core ...       37,999\n",
       "24  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...       24,990\n",
       "25  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...     2,16,327\n",
       "26  Life Digital Laptop 15.6-inch (39.62 cms) (Int...       91,999\n",
       "27  Lenovo 2019 Yoga C930 2-in-1 13.9\" 4K UHD Touc...       80,990\n",
       "28  Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...          NaN\n",
       "29  Acer Swift 3X 14\" FHD IPS Display Ultra Thin a...          NaN\n",
       "0   HP 15 (2021) Thin & Light 11th Gen Core i3 Lap...       42,499\n",
       "1   HP 15 (2021) Thin & Light Ryzen 3-3250 Laptop,...       35,695\n",
       "2   HP 15 Entry Level 15.6-inch (39.62 cms) HD Lap...       26,611\n",
       "3   HP 15 Intel Pentium Gold 6405U Processor Entry...       24,990\n",
       "4   Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...       26,999\n",
       "5   ASUS VivoBook 14 (2020) Intel Quad Core Pentiu...       42,499\n",
       "6   HP 15 AMD Athlon 15.6\" (39.62cms) HD Laptop (S...       19,800\n",
       "7   HP 15 (2021) Thin & Light 11th Gen Core i3 Lap...       50,769\n",
       "8   AVITA Essential NE14A2INC433-MB 14\" (35.56cms)...       39,939\n",
       "9   HP 15(2021) 5th Gen Ryzen 5 5500U Laptop with ...       25,990\n",
       "10  Dell Inspiron 3501 15.6\" (39.62 cms) FHD AG Di...       59,970\n",
       "11  HP Chromebook 14a-na0003TU 14-inch (35.56 cms)...       36,990\n",
       "12  HP 15 (2021) Thin & Light 11th Gen Core i5 Lap...       25,990\n",
       "13  HP 14 Ultra Thin & Light 14\" (35.56cms) Laptop...       67,990\n",
       "14  HP Chromebook 14a-na0002TU Laptop (Celeron N40...       29,390\n",
       "15  HP Pavilion (2021) Thin & Light 11th Gen Core ...       29,740\n",
       "16  (Renewed) HP Elitebook Laptop 640G1 Intel Core...       19,990\n",
       "17  Lenovo Ideapad Slim 3 AMD Athlon Silver 3050U ...       44,490\n",
       "18  (Renewed) Fujitsu Intel Core i5 3340M 15.6-Inc...       34,990\n",
       "19  Lenovo IdeaPad S145 10th Gen Intel Core i5 15....       30,873\n",
       "20  ASUS VivoBook 14 (2020) Intel Core i3-1005G1 1...       51,490\n",
       "21  Lenovo Ideapad Slim 3 AMD Ryzen 3 15.6 inch (3...       51,390\n",
       "22  Dell Inspiron 3505 15.6\" FHD Display Laptop (R...       35,990\n",
       "23  HP 14 4th Gen Ryzen 5 5500U 14-inch(35.6 cm) F...       22,990\n",
       "24  Lenovo IdeaPad Slim 3 10th Gen Intel Core i3 1...       40,990\n",
       "25  ASUS VivoBook 15 (2020), 39.6 cm HD, Dual Core...       62,999\n",
       "26  HP 15 (2021) Thin & Light Ryzen 3-3250 Laptop,...       50,856\n",
       "27  Asus X509MA-BR270T/ Silver/ Intel Celeron N402...          NaN\n",
       "28  HP 15 Thin & Light 15.6\" (39.62cms) FHD Laptop...          NaN\n",
       "29  Lenovo IdeaPad Flex 5 11th Gen Intel Core i3 1...          NaN"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concantinated data.\n",
    "final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
